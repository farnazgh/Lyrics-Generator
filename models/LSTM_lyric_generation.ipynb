{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"songlyrics4.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"CcvLaLwLgYpg","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 32\n","\n","SUBSET = 1000\n","MIN_WORD_FREQUENCY = 10\n","SEQUENCE_LEN = 5\n","EPOCH = 15"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o5vtDmxtBwXL","colab_type":"code","colab":{}},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_T1QphKBz8p","colab_type":"code","outputId":"b7882d79-4f63-430a-ee37-e487091a1913","executionInfo":{"status":"ok","timestamp":1572343470412,"user_tz":-60,"elapsed":4796,"user":{"displayName":"arash morteza","photoUrl":"","userId":"15684329459960306040"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","link = 'https://drive.google.com/open?id=1fnY95CZFNVxFm35CEXAz0Obogprw2RFO'\n","fluff, id = link.split('=')\n","\n","print (id)\n","\n","downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('Folk-country Lyrics separated by quotation marks_utf-8 and CR-LF line separator.txt')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["1fnY95CZFNVxFm35CEXAz0Obogprw2RFO\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Of0XeZwB1I8f","colab_type":"code","outputId":"c41fcae5-b59c-4f04-9a2f-ff66ec917c68","executionInfo":{"status":"ok","timestamp":1572343471002,"user_tz":-60,"elapsed":5362,"user":{"displayName":"arash morteza","photoUrl":"","userId":"15684329459960306040"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["link = 'https://drive.google.com/open?id=1fnY95CZFNVxFm35CEXAz0Obogprw2RFO'\n","fluff, id = link.split('=')\n","\n","print (id)\n","\n","downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('Folk-country Lyrics separated by quotation marks_utf-8 and CR-LF line separator.txt')\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["1fnY95CZFNVxFm35CEXAz0Obogprw2RFO\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jkEfEIikB2TI","colab_type":"code","outputId":"49fb7daf-1190-4c26-a968-16dcfcc41bd8","executionInfo":{"status":"ok","timestamp":1572343472988,"user_tz":-60,"elapsed":7326,"user":{"displayName":"arash morteza","photoUrl":"","userId":"15684329459960306040"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["#songdata_UTF8_clean.txt - there were some qoutes in the file that were removed (also double space replaced by one) \n","# then the lyric column were extracted and converted to the utf8 format\n","\n","#open file and save it in to list \n","with open('songdata_UTF8_clean.txt', 'r') as content_file:\n","    content = content_file.read()\n","songlyrics = content.split(\"\\\"\")\n","\n","\n","#cleaning - removing empty elements from the list\n","clean_songlyrics = []\n","for item in songlyrics:\n","  if len(item)>1:\n","    clean_songlyrics.append(item)\n","# print(clean_songlyrics[0])\n","\n","\n","#make a list(lyrics) of list(sentences)\n","lyrics = []\n","for l in clean_songlyrics:\n","#   l = l.replace(\"\\n\", \"\")\n","#   l = l.replace(\"\\n\", \"\")\n","  sentences = l.split(\"\\n\")\n","  lyrics.append(sentences)\n","  \n","\n","\n","#cleaning - removing empty elements from sentences of each lyric\n","    \n","lyrics = [[s for s in l if len(s)>1] for l in lyrics ]\n","print(lyrics[19])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["['Puedes escuchar Fernando? ', 'Me recuerda tiempo atras ', 'Estrellas y una noche alla ', 'En la lumbre azul Fernando ', 'Tarareabas tu cancion ', 'Con ese suave guitarrear ', 'Yo podia escuchar ', 'Esos tambores con un sordo redoblar ', 'Se acercaban mas fernando ', 'Y el momento que pasaba ', 'Parecia eternidad ', 'Y senti temor Fernando ', 'Por la vida y juventud ', 'Nadie pensaba en morir ', 'Y no siento hoy verguenza al ', 'Confesar que tuve ', 'Ganas de llorar ', 'Algo habia alrededor quiza ', 'De claridad Fernando ', 'Que brillaba por nosotros dos ', 'En proteccion Fernando ', 'No pensabamos jamas perder ', 'Ni echar atras ', 'Si tuviera que volverlo a hacer ', 'Lo haria ya Fernando ', 'Si tuviera que volverlo a hacer ', 'Lo haria ya Fernando ', 'La vejez llego Fernando ', 'Y con ella una paz ', 'Que hoy logramos disfrutar ', 'Se durmio el tambor Fernando ', 'Paraciera que fue ayer ', 'Que lo vivimos tu y yo ', 'Y en tus ojos veo aun ', 'Aquel orgullo que refleja tu valor. ', 'Algo habia alrededor quiza ', 'De claridad Fernando ', 'Que brillaba por nosotros dos ', 'En proteccion Fernando ', 'No pensabamos jamas perder ', 'Ni echar atras ', 'Si tuviera que volverlo a hacer ', 'Lo haria ya Fernando ', 'Si tuviera que volverlo a hacer ', 'Lo haria ya Fernando ', 'Algo habia alrededor quiza ', 'De claridad Fernando ', 'Que brillaba por nosotros dos ', 'En proteccion Fernando ', 'No pensabamos jamas perder ', 'Ni echar atras ', 'Si tuviera que volverlo a hacer ', 'Lo haria ya Fernando ', 'Si tuviera que volverlo a hacer ', 'Lo haria ya Fernando ', 'Si tuviera que volverlo a hacer ', 'Lo haria ya Fernando ', '[Repeata y fade ]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J52YUK7b1xND","colab_type":"code","outputId":"32ccb92b-4bd0-4f65-b97d-7a023cb4f079","executionInfo":{"status":"ok","timestamp":1572343473202,"user_tz":-60,"elapsed":7520,"user":{"displayName":"arash morteza","photoUrl":"","userId":"15684329459960306040"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["#open file and save it in to list \n","with open('Folk-country Lyrics separated by quotation marks_utf-8 and CR-LF line separator.txt', 'r') as content_file:\n","    content = content_file.read()\n","songlyrics = content.split(\"\\\"\")\n","\n","\n","#cleaning - removing empty elements from the list\n","clean_songlyrics = []\n","for item in songlyrics:\n","  if len(item)>1:\n","    clean_songlyrics.append(item)\n","# print(clean_songlyrics[0])\n","\n","\n","#make a list(lyrics) of list(sentences)\n","lyrics = []\n","for l in clean_songlyrics:\n","#   l = l.replace(\"\\n\", \"\")\n","#   l = l.replace(\"\\n\", \"\")\n","  sentences = l.split(\"\\n\")\n","  lyrics.append(sentences)\n","  \n","\n","\n","#cleaning - removing empty elements from sentences of each lyric\n","    \n","lyrics = [[s for s in l if len(s)>1] for l in lyrics ]\n","print(lyrics[19])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[\"I know there's nothing worse than a bad goodbye\", \"And you think you'll feel better if you have a good cry\", \"But save those tears for tomorrow when there's nothing better to do\", \"It's a beautiful night, don't waste it on the blues\", 'Time is all it takes for a broken heart to mend', \"And sooner or later you know you'll try to love again\", \"So why not start tonight, you've only got the hurtin' to lose\", \"There's a full moon out, don't waste it on the blues\", \"Don't waste one more minute\", \"Leavin' a bad break, to keep you home in the dark\", \"There's nothin' like a walk in the moonlight\", 'To let love run away with your heart', 'You could turn on your stereo and play your saddest songs', 'Sit by your window and stare out all night long', \"But if you look up you'll see the stars are just too bright to refuse\", \"It's a beautiful night, don't waste it on the blues\"]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OAzr5CCJCAus","colab_type":"code","outputId":"bd809be5-2bf9-4af6-86f7-7ed4cbdc8066","executionInfo":{"status":"ok","timestamp":1572343478729,"user_tz":-60,"elapsed":13022,"user":{"displayName":"arash morteza","photoUrl":"","userId":"15684329459960306040"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["#cleaning - removing brackets from the main list (lyrics)\n","import re\n","regex = re.compile(\".*?\\[(.*?)\\]\")\n","\n","bracket = []\n","for i in range(len(lyrics)):\n","\n","  for j in range(len(lyrics[i])):\n","\n","    result = re.findall(regex, lyrics[i][j])\n","\n","    for item in result:\n","\n","      #keep them in the bracket list\n","      if item not in bracket:\n","        bracket.append(item)\n","\n","      #remove the brackets from the sentences\n","      lyrics[i][j] = lyrics[i][j].replace(\"[\"+item+\"]\", \"\")\n","    \n","    \n","  #cleaning- remove empty elements (sentences) appeared on each lyric\n","  lyrics[i] = [s for s in lyrics[i] if len(s)>1]\n","        \n","    \n","    \n","# print(bracket)\n","print(lyrics[19])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[\"I know there's nothing worse than a bad goodbye\", \"And you think you'll feel better if you have a good cry\", \"But save those tears for tomorrow when there's nothing better to do\", \"It's a beautiful night, don't waste it on the blues\", 'Time is all it takes for a broken heart to mend', \"And sooner or later you know you'll try to love again\", \"So why not start tonight, you've only got the hurtin' to lose\", \"There's a full moon out, don't waste it on the blues\", \"Don't waste one more minute\", \"Leavin' a bad break, to keep you home in the dark\", \"There's nothin' like a walk in the moonlight\", 'To let love run away with your heart', 'You could turn on your stereo and play your saddest songs', 'Sit by your window and stare out all night long', \"But if you look up you'll see the stars are just too bright to refuse\", \"It's a beautiful night, don't waste it on the blues\"]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yt6Ow-MeCDxm","colab_type":"code","outputId":"892da17e-071d-4a7b-eebf-8251134f1bf9","executionInfo":{"status":"ok","timestamp":1572343478734,"user_tz":-60,"elapsed":13010,"user":{"displayName":"arash morteza","photoUrl":"","userId":"15684329459960306040"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["print(len(lyrics))\n","lyrics = lyrics[0:SUBSET]\n","print(len(lyrics))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["21403\n","1000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IA-Y4rbVYv9t","colab_type":"code","outputId":"424e61cf-6ee1-419c-9c79-d0bff864fce2","executionInfo":{"status":"ok","timestamp":1572343478738,"user_tz":-60,"elapsed":12995,"user":{"displayName":"arash morteza","photoUrl":"","userId":"15684329459960306040"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["for i in range(len(lyrics)):\n","  for j in range(len(lyrics[i])):\n","    lyrics[i][j] += \"\\n\"\n","    \n","print(lyrics[0])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["['When the last breath of life\\n', 'Is gone from my body\\n', 'And my lips are as cold as the sea\\n', \"When my friends gather 'round\\n\", 'For my farewell party\\n', 'Want you pretend you love me\\n', 'There will be flowers from those\\n', \"Who cry when I'm gone\\n\", 'And leave you in this world alone\\n', \"I know you'll have fun\\n\", 'At my farewell party\\n', \"I know you'll be glad when I'm gone\\n\", \"Don't be mad at me for wanting to keep you\\n\", 'Till my life on this old world is through\\n', \"You'll be free at the end of my farewell party\\n\", \"But I'll go away loving you\\n\", \"Oh, I know you'll be glad when I'm gone\\n\"]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XhpCi-BACHZW","colab_type":"code","outputId":"baa59d31-8a17-4d1f-ad47-36541d7d3748","executionInfo":{"status":"ok","timestamp":1572343478740,"user_tz":-60,"elapsed":12977,"user":{"displayName":"arash morteza","photoUrl":"","userId":"15684329459960306040"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["#model - based on this link : https://medium.com/coinmonks/word-level-lstm-text-generator-creating-automatic-song-lyrics-with-neural-networks-b8a1617104fb\n","\n","text_in_words = [w.lower()   for l in lyrics for s in l for w in s.split(' ') if len(w)>0]\n","# print(text_in_words[0:9])\n","\n","\n","#---------------Calculate word frequency\n","\n","word_freq = {}\n","for word in text_in_words:\n","    word_freq[word] = word_freq.get(word, 0) + 1\n","    \n","ignored_words = set()\n","for k, v in word_freq.items():\n","    if word_freq[k] < MIN_WORD_FREQUENCY:\n","        ignored_words.add(k)\n","        \n","words = set(text_in_words)\n","print('Unique words before ignoring:', len(words))\n","print('Ignoring words with frequency <', MIN_WORD_FREQUENCY)\n","words = sorted(set(words) - ignored_words)\n","print('Unique words after ignoring:', len(words))\n","\n","word_indices = dict((c, i) for i, c in enumerate(words))\n","indices_word = dict((i, c) for i, c in enumerate(words))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Unique words before ignoring: 12034\n","Ignoring words with frequency < 10\n","Unique words after ignoring: 1487\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jcoP3MZfCMGd","colab_type":"code","outputId":"c8205a1b-c12c-46ba-93c7-9b54340ecc80","executionInfo":{"status":"ok","timestamp":1572343478990,"user_tz":-60,"elapsed":13205,"user":{"displayName":"arash morteza","photoUrl":"","userId":"15684329459960306040"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# ------------cut the text in semi-redundant sequences of SEQUENCE_LEN words\n","STEP = 1\n","\n","sentences = []\n","next_words = []\n","ignored = 0\n","for i in range(0, len(text_in_words) - SEQUENCE_LEN, STEP):\n","    # Only add sequences where no word is in ignored_words\n","    if len(set(text_in_words[i: i+SEQUENCE_LEN+1]).intersection(ignored_words)) == 0:\n","        sentences.append(text_in_words[i: i + SEQUENCE_LEN])\n","        next_words.append(text_in_words[i + SEQUENCE_LEN])\n","    else:\n","        ignored = ignored+1\n","print('Ignored sequences:', ignored)\n","print('Remaining sequences:', len(sentences))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Ignored sequences: 85405\n","Remaining sequences: 48387\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X7c0ThRvCPf_","colab_type":"code","outputId":"3fa74798-4990-499e-b3c6-9d5d526f6a52","executionInfo":{"status":"ok","timestamp":1572343478998,"user_tz":-60,"elapsed":13192,"user":{"displayName":"arash morteza","photoUrl":"","userId":"15684329459960306040"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["#-------------Shuffle and split training set\n","import numpy as np\n","\n","def shuffle_and_split_training_set(sentences_original, next_original, percentage_test=2):\n","    # shuffle at unison\n","    print('Shuffling sentences')\n","\n","    tmp_sentences = []\n","    tmp_next_word = []\n","    for i in np.random.permutation(len(sentences_original)):\n","        tmp_sentences.append(sentences_original[i])\n","        tmp_next_word.append(next_original[i])\n","\n","    cut_index = int(len(sentences_original) * (1.-(percentage_test/100.)))\n","    x_train, x_test = tmp_sentences[:cut_index], tmp_sentences[cut_index:]\n","    y_train, y_test = tmp_next_word[:cut_index], tmp_next_word[cut_index:]\n","\n","    print(\"Size of training set = %d\" % len(x_train))\n","    print(\"Size of test set = %d\" % len(y_test))\n","    return x_train, y_train, x_test, y_test\n","\n","  \n","sentences, next_words, sentences_test, next_words_test = shuffle_and_split_training_set(sentences, next_words)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Shuffling sentences\n","Size of training set = 47419\n","Size of test set = 968\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wd9Ger5eCS7L","colab_type":"code","outputId":"cc239509-7bed-40bc-e266-17f62057125e","executionInfo":{"status":"ok","timestamp":1572343480932,"user_tz":-60,"elapsed":15109,"user":{"displayName":"arash morteza","photoUrl":"","userId":"15684329459960306040"}},"colab":{"base_uri":"https://localhost:8080/","height":292}},"source":["#------------Building the model\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional, Embedding, InputLayer\n","\n","model = Sequential()\n","model.add(Embedding(input_dim=len(words), output_dim=1024))\n","model.add(Bidirectional(LSTM(128)))\n","model.add(Dropout(0.2))\n","model.add(Dense(len(words)))\n","model.add(Activation('softmax'))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ohHaRs1mCXWP","colab_type":"code","colab":{}},"source":["def generator(sentence_list, next_word_list, batch_size):\n","    index = 0\n","    while True:\n","        x = np.zeros((batch_size, SEQUENCE_LEN), dtype=np.int32)\n","        y = np.zeros((batch_size), dtype=np.int32)\n","        for i in range(batch_size):\n","            for t, w in enumerate(sentence_list[index % len(sentence_list)]):\n","                x[i, t] = word_indices[w]\n","            y[i] = word_indices[next_word_list[index % len(sentence_list)]]\n","            index = index + 1\n","        yield x, y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XFgyP7DuTlaa","colab_type":"code","colab":{}},"source":["def on_epoch_end(epoch, logs):\n","    # Function invoked at end of each epoch. Prints generated text.\n","    examples_file.write('\\n----- Generating text after Epoch: %d\\n' % epoch)\n","\n","    # Randomly pick a seed sequence\n","    seed_index = np.random.randint(len(sentences+sentences_test))\n","    seed = (sentences+sentences_test)[seed_index]\n","\n","    for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n","        sentence = seed\n","        examples_file.write('----- Diversity:' + str(diversity) + '\\n')\n","        examples_file.write('----- Generating with seed:\\n\"' + ' '.join(sentence) + '\"\\n')\n","        examples_file.write(' '.join(sentence))\n","\n","        for i in range(50):\n","            x_pred = np.zeros((1, SEQUENCE_LEN, len(words)))\n","            for t, word in enumerate(sentence):\n","                x_pred[0, t, word_indices[word]] = 1.\n","\n","            preds = model.predict(x_pred, verbose=0)[0]\n","            next_index = sample(preds, diversity)\n","            next_word = indices_word[next_index]\n","\n","            sentence = sentence[1:]\n","            sentence.append(next_word)\n","\n","            examples_file.write(\" \"+next_word)\n","        examples_file.write('\\n')\n","    examples_file.write('='*80 + '\\n')\n","    examples_file.flush()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G8ZMiGXECaBC","colab_type":"code","outputId":"6e8106ee-21dd-4fde-e2f1-bd776c095e5b","executionInfo":{"status":"ok","timestamp":1572346020140,"user_tz":-60,"elapsed":2554281,"user":{"displayName":"arash morteza","photoUrl":"","userId":"15684329459960306040"}},"colab":{"base_uri":"https://localhost:8080/","height":975}},"source":["#-----------------training model\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n","\n","\n","from keras.callbacks import LambdaCallback, ModelCheckpoint, EarlyStopping\n","file_path = \"./checkpoints/LSTM_LYRICS-epoch{epoch:03d}-words%d-sequence%d-minfreq%d-\" \\\n","                \"loss{loss:.4f}-acc{acc:.4f}-val_loss{val_loss:.4f}-val_acc{val_acc:.4f}\" % \\\n","                (len(words), SEQUENCE_LEN, MIN_WORD_FREQUENCY)\n","\n","checkpoint = ModelCheckpoint(file_path, monitor='val_acc', save_best_only=True)\n","print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n","early_stopping = EarlyStopping(monitor='val_acc', patience=5)\n","callbacks_list = [checkpoint, print_callback, early_stopping]\n","\n","examples_file = open(\"examples.txt\", \"w\")\n","\n","\n","\n","# BATCH_SIZE = 32\n","model.fit_generator(generator(sentences, next_words, BATCH_SIZE),\n","                        steps_per_epoch=int(len(sentences)/BATCH_SIZE) + 1,\n","                        epochs=EPOCH, #100\n","                        validation_data=generator(sentences_test, next_words_test, BATCH_SIZE),\n","                        validation_steps=int(len(sentences_test)/BATCH_SIZE) + 1)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Epoch 1/15\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","1482/1482 [==============================] - 173s 116ms/step - loss: 5.4742 - acc: 0.0991 - val_loss: 4.8824 - val_acc: 0.1522\n","Epoch 2/15\n","1482/1482 [==============================] - 171s 115ms/step - loss: 4.2537 - acc: 0.2184 - val_loss: 4.2132 - val_acc: 0.2379\n","Epoch 3/15\n","1482/1482 [==============================] - 171s 116ms/step - loss: 3.4286 - acc: 0.3276 - val_loss: 3.8225 - val_acc: 0.3145\n","Epoch 4/15\n","1482/1482 [==============================] - 170s 115ms/step - loss: 2.7997 - acc: 0.4245 - val_loss: 3.6215 - val_acc: 0.3690\n","Epoch 5/15\n","1482/1482 [==============================] - 171s 115ms/step - loss: 2.3010 - acc: 0.5068 - val_loss: 3.5014 - val_acc: 0.3972\n","Epoch 6/15\n","1482/1482 [==============================] - 170s 115ms/step - loss: 1.8871 - acc: 0.5825 - val_loss: 3.4128 - val_acc: 0.4375\n","Epoch 7/15\n","1482/1482 [==============================] - 168s 114ms/step - loss: 1.5525 - acc: 0.6476 - val_loss: 3.4769 - val_acc: 0.4325\n","Epoch 8/15\n","1482/1482 [==============================] - 168s 113ms/step - loss: 1.2770 - acc: 0.7054 - val_loss: 3.5122 - val_acc: 0.4536\n","Epoch 9/15\n","1482/1482 [==============================] - 168s 113ms/step - loss: 1.0459 - acc: 0.7563 - val_loss: 3.5543 - val_acc: 0.4667\n","Epoch 10/15\n","1482/1482 [==============================] - 167s 113ms/step - loss: 0.8747 - acc: 0.7948 - val_loss: 3.5452 - val_acc: 0.4788\n","Epoch 11/15\n","1482/1482 [==============================] - 167s 113ms/step - loss: 0.7306 - acc: 0.8254 - val_loss: 3.6571 - val_acc: 0.4798\n","Epoch 12/15\n","1482/1482 [==============================] - 169s 114ms/step - loss: 0.6350 - acc: 0.8526 - val_loss: 3.7512 - val_acc: 0.4768\n","Epoch 13/15\n","1482/1482 [==============================] - 168s 114ms/step - loss: 0.5565 - acc: 0.8681 - val_loss: 3.8470 - val_acc: 0.4839\n","Epoch 14/15\n","1482/1482 [==============================] - 169s 114ms/step - loss: 0.4995 - acc: 0.8811 - val_loss: 3.8596 - val_acc: 0.4889\n","Epoch 15/15\n","1482/1482 [==============================] - 168s 113ms/step - loss: 0.4625 - acc: 0.8897 - val_loss: 3.8893 - val_acc: 0.4950\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fad94bba400>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"sPt9k9k0Tphf","colab_type":"code","colab":{}},"source":["def sample(preds, temperature=1.0):\n","    # helper function to sample an index from a probability array\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GiLqIC0HTyDp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"3ba8f474-eb97-4b70-867a-bedbeb07573b","executionInfo":{"status":"ok","timestamp":1572346021071,"user_tz":-60,"elapsed":2555187,"user":{"displayName":"arash morteza","photoUrl":"","userId":"15684329459960306040"}}},"source":["sentence = ['i', 'like', 'you', 'much', 'more']\n","\n","x_pred = np.zeros((SEQUENCE_LEN, len(words)))\n","# print(word_indices['i'])\n","for t, word in enumerate(sentence):\n","#   print(\"here\")\n","  x_pred[t, word_indices[word]] = 1.\n","  \n","\n","\n","diversity  = 10\n","preds = model.predict(x_pred, verbose=0)[0]\n","next_index = sample(preds, diversity)\n","next_word = indices_word[next_index]\n","print(next_word)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["around\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"98lf3jSDT2tX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":923},"outputId":"ff3f25fc-72dc-429a-8b0b-56922907644b","executionInfo":{"status":"ok","timestamp":1572346051802,"user_tz":-60,"elapsed":2585908,"user":{"displayName":"arash morteza","photoUrl":"","userId":"15684329459960306040"}}},"source":["seed =  ['i', 'like', 'you', 'much', 'more']\n","sentence =  ['i', 'like', 'you', 'much', 'more']\n","diversity  = 10 # what is the right one???????\n","  \n","for i in range(50):\n","  \n","  x_pred = np.zeros((SEQUENCE_LEN, len(words)))\n","  for t, word in enumerate(seed):\n","    x_pred[t, word_indices[word]] = 1.\n","    \n","  \n","  preds = model.predict(x_pred, verbose=0)[0]\n","  next_index = sample(preds, diversity)\n","  next_word = indices_word[next_index]\n","  \n","  sentence.append(next_word)\n","  \n","  seed = seed[1:]\n","  seed.append(next_word)\n","  \n","  print(\"sent--\"+str(sentence))\n","\n","print(sentence)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["sent--['i', 'like', 'you', 'much', 'more', 'do']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\"]\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\"]\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\"]\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\"]\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow', 'side']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow', 'side', 'them\\n']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow', 'side', 'them\\n', 'bed']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow', 'side', 'them\\n', 'bed', 'after']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow', 'side', 'them\\n', 'bed', 'after', 'care']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow', 'side', 'them\\n', 'bed', 'after', 'care', 'knows']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow', 'side', 'them\\n', 'bed', 'after', 'care', 'knows', 'dark']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow', 'side', 'them\\n', 'bed', 'after', 'care', 'knows', 'dark', 'eyes\\n']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow', 'side', 'them\\n', 'bed', 'after', 'care', 'knows', 'dark', 'eyes\\n', 'can']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow', 'side', 'them\\n', 'bed', 'after', 'care', 'knows', 'dark', 'eyes\\n', 'can', 'so']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow', 'side', 'them\\n', 'bed', 'after', 'care', 'knows', 'dark', 'eyes\\n', 'can', 'so', 'mouth']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow', 'side', 'them\\n', 'bed', 'after', 'care', 'knows', 'dark', 'eyes\\n', 'can', 'so', 'mouth', 'angels']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow', 'side', 'them\\n', 'bed', 'after', 'care', 'knows', 'dark', 'eyes\\n', 'can', 'so', 'mouth', 'angels', 'lord']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow', 'side', 'them\\n', 'bed', 'after', 'care', 'knows', 'dark', 'eyes\\n', 'can', 'so', 'mouth', 'angels', 'lord', 'stand\\n']\n","sent--['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow', 'side', 'them\\n', 'bed', 'after', 'care', 'knows', 'dark', 'eyes\\n', 'can', 'so', 'mouth', 'angels', 'lord', 'stand\\n', 'wait\\n']\n","['i', 'like', 'you', 'much', 'more', 'do', 'please', 'it', 'dressed', 'mary', 'as', 'once', 'said\\n', 'ring\\n', 'sang', \"world's\", 'pack', 'says', 'ride', 'are\\n', 'joe\\n', 'thing', 'drop', 'can', 'sight\\n', 'dream\\n', \"you're\", 'help', 'above', 'morning\\n', 'no\\n', \"ain't\", 'heart', 'brought', 'built', 'radio', \"they'd\", 'coming', 'leaving', 'somehow', 'side', 'them\\n', 'bed', 'after', 'care', 'knows', 'dark', 'eyes\\n', 'can', 'so', 'mouth', 'angels', 'lord', 'stand\\n', 'wait\\n']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zICtUaYlayFW","colab_type":"text"},"source":["features:\n","\n","*   SUBSET = 1000\n","*   MIN_WORD_FREQUENCY = 15\n","*   SEQUENCE_LEN = 1 \n","*   EPOCH = 10\n","\n","result:\n","\n","a bunch of 'i' and 'and'"]},{"cell_type":"markdown","metadata":{"id":"hHe7nz0vvHjX","colab_type":"text"},"source":["features:\n","\n","*   SUBSET = 1000\n","*   MIN_WORD_FREQUENCY = 15\n","*   SEQUENCE_LEN = 3 --------------\n","*   EPOCH = 10\n","\n","result:\n","\n","a bunch of 'i' , 'and' , 'i'll' "]}]}